---
title: "Census Pull"
author: "Ethan Tenison"
date: "`r format(Sys.Date(), '%B %d, %Y') `"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

library(tidyverse)
library(tidycensus)
```


# ACS Variables 

* Wealth
  + QRICH = Percent Households Earning over $200,000 annually
  + MDHSEVAL = Median Housing Value
  + PERCAP = Per Capita Income
* Language & Education 
  + QESL = Percent Speaking English as a Second Language with Limited Proficiency
  + QSPANISH =  Percent Hispanic 
  + QED12LES = Percent Less than high school education for population over 25 years and older
* Elderly
  + QSSBEN = Percent Households Receiving Social Security Benefits
  + QAGEDEP = Percent Population under 5 years or 65 and over
  + MEDAGE = Median age 
* Housing Status 
  + PPUNIT = People per Unit (Average household size)
  + QFAM = Percent Children Living with both parents 
* Social Status
  + QCVLUN = Percent Unemployment for Civilian in Labor Force 16 Years and Over
  + QBLACK = Percent Black or African American Alone
  + QNOAUTO = Percent Housing Units with No Car
  + QPOVTY = Percent Poverty
* Gender
  + QFEMALE = Percent Female 
  + QFEMLBR = Percent Female Participation in Labor Force
  
  
# Variable Search

* Used to select the variables. Careful consideration must be taken when pulling variables from different tables. Often times the population is not the same. 

```{r v_search}

v19 <- load_variables(2019, "acs5", cache = TRUE)

```

# Using `Tidycensus`

* First you need to define the variables you would like to pull and the geographic region. In this case, all the data was pulled for the 10-County CAPCOG region. The results data frame is in long format and must be pivoted wider for analysis.You can find documentation about the package on the [Tidycensus](https://walker-data.com/tidycensus/) website. 


```{r tidycensus}

#acs variables 
vars <- c(	
"QRICH" = "B19001_017", #need to divide households 
"households" = "B09019_002",
"MDHSEVAL" = 	"B25077_001",
"PERCAP" = "B19301_001",
"QESL-Spanish" = "B06007_005", #need to be added together and divided by pop 
"QESL-Other" = "B06007_008",
"QSPANISH" = "B03001_003", # need to divide by pop
"POP" = "B03001_001",
"QED12LES" = "B16010_002", # divide by pop
"QSSBEN" = "B19055_002", #divide by pop 
"QAGEDEP-under5" = "B06001_002",#add together and divide by pop
"QAGEDEP-over65" = "B18135_024",
"MEDAGE"= "B07002_001",
"PPUNIT" = "B25010_001",
"QFAM_under6" = "B05009_003", #add together and divide by children
"QFAM_to17" = "B05009_021",
"children" = "B05009_001",
"QCVLUN" = "B23025_005", # divide by pop 
"QBLACK" = "B18101B_001", #divide by pop,
"QNOAUTO" = "B08203_002", #divide by households 
"QPOVTY" = "B17020_002", #divide by pop
"QFEMALE" = "B01001_026", # divide by pop
"wlab1" = "C23002A_004", #can't really pull female labor participation except by race
"wlab2" = "C23002B_004", #Then divide by over 16
"wlab3" = "C23002C_004",
"wlab4" = "C23002D_004",
"wlab5" = "C23002E_004",
"wlab6" = "C23002F_004",
"wlab7" = "C23002G_004",
"f1" = "B01001_030", #pulling pop by age is actually the worst!
"f2" = "B01001_031",
"f3" = "B01001_032",
"f4" = "B01001_033",
"f5" = "B01001_034",
"f6" = "B01001_035",
"f7" = "B01001_036",
"f8" = "B01001_037",
"f9" = "B01001_038",
"f10" = "B01001_039",
"f11" = "B01001_040",
"f12" = "B01001_041",
"f13" = "B01001_042",
"f14" = "B01001_043",
"female_over65" = "B15001_076" 
)

counties <- c("Travis", "Bastrop","Blanco", "Burnet", "Caldwell",
              "Fayette", "Hays", "Lee", "Llano", "Williamson")

#enter your key census_api_key("Your key here")
acs <-get_acs(state="TX", county = counties, geography="tract",year = 2019,
              variables=vars, geometry= F) 

df_raw <- acs |> 
  select(GEOID, variable, estimate) |> 
  pivot_wider(id_cols = GEOID, 
              names_from = variable,
              values_from = estimate) 

```

# Data cleaning

* Many of the variables from the acs come as total estimates, so they need to be divided by the population accordingly. Additionally, some variables have much narrower populations, such as women in the labor force, and require more adjustments. `NA` values and infinite values also have to be removed from the resulting dataframe. In most cases `NA` were substituted with 0, but infinite values were removed.

```{r dc}

df <- df_raw |>
  mutate(
    QRICH = QRICH / households,
    QESL = (`QESL-Spanish` + `QESL-Other`) / POP,
    QSPANISH = QSPANISH / POP,
    QED12LES = QED12LES / POP,
    QSSBEN = QSSBEN / POP,
    QAGEDEP = (`QAGEDEP-under5` + `QAGEDEP-over65`) / POP,
    QFAM = (QFAM_under6 + QFAM_to17) / children,
    QCVLUN = QCVLUN / POP,
    QBLACK = QBLACK / POP,
    QNOAUTO = QNOAUTO / households,
    QPOVTY = QPOVTY / POP,
    QFEMALE = QFEMALE / POP,
    QFEMLBR = (wlab1 + wlab2 + wlab3 + wlab4 + wlab5 + wlab6 + wlab7) /
      (
        f1 + f2 + f3 + f4 + f5 + f6 + f7 + f8 + f9 + f10 + f11 + f12 + f13 + f14 + female_over65
      )
  ) |>
  select(
    -c(
      #Variables to remove
      POP,
      children,
      QFAM_under6,
      QFAM_to17,
      households,
      female_over65,
      `QAGEDEP-under5`,
      `QAGEDEP-over65`,
      `QESL-Spanish`,
      `QESL-Other`,
      starts_with("wlab"),
      "f1","f2","f3" ,"f4","f5" ,"f6" ,"f7" ,"f8" ,"f9" ,"f10" ,"f11" ,"f12","f13" ,
      "f14" ,
    )
  ) |> 
  mutate(across(everything(),~replace_na(.x,0))) |> 
  filter(across(everything(), ~!is.infinite(.)))

head(df)

```


# Principal Components 

* Each variable is first centered on zero and the variance is unit scaled. This is done so that all of the variables have the same reference point and those with large variances don't dominate the analysis

```{r pca}

pc <- prcomp(df[,-1],#have to take our geoid column
             center = TRUE,
             scale. = TRUE)

#elements stored in the pc list
attributes(pc)
```
# Analysing deviations and loadings

* 


```{r loadings}

print(pc)

```



# PCA Variation 

* How much variation is contained within each principal component 
```{r pca_variation}

pca_var <- pc$sdev^2
pca_var_perc <- round(pca_var/sum(pca_var) * 100, 1)
barplot(pca_var_perc, main = "Variation Plot", xlab = "PCs", ylab = "Percentage Variance", ylim = c(0, 100))

```

# Assign weight


```{r rotation}

PC1 <- pc$rotation[,1]
PC1_scores <- abs(PC1)
PC1_scores_ordered <- sort(PC1_scores, decreasing = TRUE)
names(PC1_scores_ordered)

```

# More practicing 


```{r pysch}

library(psych)

PCA_results <- princomp(df[,-1])
df$index <- PCA_results$scores




```


# Let's plots to inspect

```{r plots}

counties <- c("Travis", "Bastrop","Blanco", "Burnet", "Caldwell",
              "Fayette", "Hays", "Lee", "Llano", "Williamson")

#enter your key census_api_key("Your key here")
acs2 <-get_acs(state="TX", county = "Travis", geography="tract",year = 2019,
              variables="B03001_001", geometry= T) 

tracts <- acs2 |> 
  distinct(GEOID, .keep_all = TRUE) |> 
  select(GEOID, geometry)

library(leaflet)
library(sf)
df2 <- df |> 
  right_join(tracts, by = "GEOID") |> 
  st_as_sf() |> 
  filter(!is.na(GEOID)) |> 
  mutate(index = scale(index))

df2 <- na.omit(df2)
  

# leaflet() %>%
#     addProviderTiles("CartoDB.Positron") %>%
#     addPolygons(data = df2, weight = 2, color = ~colorQuantile("red", df$index)(index))

plot(df2["index"])
  
```


